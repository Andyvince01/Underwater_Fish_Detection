''' ðŸ’¥ vlm.py
>>> This script is used to complete prompts using the VLM model.
'''

#------------------------------------------------------------------------------------------------------------#
# 1. âš™ï¸ IMPORTS LIBRARIES AND MODULES
#------------------------------------------------------------------------------------------------------------#
import numpy as np, torch
from PIL import Image

from ultralytics.utils import Processor, VLM, VLM_CFG, VOC
from ultralytics.utils.frame_utils import img

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#------------------------------------------------------------------------------------------------------------#
# 2. ðŸŽˆ DEFINE CONSTANTS
#------------------------------------------------------------------------------------------------------------#
weights = VLM_CFG.get('weights', None)
torch_dtype = VLM_CFG.get('dtype', torch.float16)
max_new_tokens = VLM_CFG.get('max_new_tokens', 20)

#------------------------------------------------------------------------------------------------------------#
# 2. ðŸ§  INITIALIZE THE MODELS
#------------------------------------------------------------------------------------------------------------#
processor : Processor = Processor.from_pretrained(weights, device_map=DEVICE, torch_dtype=torch_dtype) if weights else None
model : VLM = VLM.from_pretrained(weights, device_map=DEVICE, torch_dtype=torch.float16) if weights else None

#------------------------------------------------------------------------------------------------------------#
# 3. ðŸš€ FUNCTIONS
#------------------------------------------------------------------------------------------------------------#

#--- Define the function to generate text from an image and a prompt ---#
def generate_text_from_image_and_prompt(image : Image.Image, prompt : str) -> str:
    ''' This function is used to generate text from a prompt using the VLM model.
    
    Parameters
    ----------
    image : Image.Image
        The image to use for the generation.
    prompt : str
        The prompt to use for the generation
        
    Returns
    -------
    str
        The generated text.

    Notes
    -----
    In case you have warnings about specifying both ``new_max_tokens`` and ``max_length``, you may disable
    the check in ``_prepare_generated_length`` in ``transformers/generation/utils.py``.
        
    Example
    -------
    >>> from PIL import Image
    >>> from vlm import generate_text_from_image_and_prompt
    >>> 
    >>> image = Image.open("path/to/image.jpg")
    >>> prompt = "A cat"
    >>> completed_prompt = generate_text_from_image_and_prompt(image, prompt)
    >>> # --> "A cat is sitting on a chair."
    '''
    inputs = processor(images=image, text=[prompt], return_tensors="pt").to(DEVICE, dtype=torch_dtype)
    generated_ids = model.generate(**inputs, max_new_tokens=max_new_tokens)
    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)
    return generated_text[0].strip()

#--- Define the function to generate a caption for an image ---#
def generate_image_caption(image : Image.Image) -> str:
    ''' Caption an image using the VLM model.
    
    Parameters
    ----------
    image : Image.Image
        The image to caption.

    Returns
    -------
    str
        The caption for the image.
        
    Example
    -------
    >>> from PIL import Image
    >>> from vlm import generate_image_caption
    >>> 
    >>> image = Image.open("path/to/image.jpg")
    >>> caption = generate_image_caption(image)
    >>> # --> "A cat is sitting on a chair."
    '''
    output = generate_text_from_image_and_prompt(image, "")
    return output

#------------------------------------------------------------------------------------------------------------#
# 3.1 ðŸš€ SECOND ANALYZER FUNCTIONS
#------------------------------------------------------------------------------------------------------------#

#--- Define the function to check if a word of the VOC set is in the caption ---#
def voc_in_caption(
    frame: np.ndarray,                                  # The frame to analyze
    vocabulary = VOC         # The vocabulary to check in the caption
) -> bool:
    ''' 
    This function is used to check if the caption generated by the VLM model contains a word from the VOC set.
    
    Parameters
    ----------
    frame : np.ndarray
        The frame to analyze.
    captioning_prompt : str, optional
        The captioning prompt, by default "".
    vocabulary : set[str] | frozenset[str], optional
        The vocabulary to check in the caption, by default VOC.
    
    Returns
    -------
    bool
        A boolean indicating if the caption contains a word from the VOC set.
    '''
    caption = generate_image_caption(img(frame))
    return any(word.lower() in caption.lower() for word in vocabulary)

#--- Define the function to check if the answer contains the word "yes" ---#
def answers_yes(frame: np.ndarray, question: str) -> bool:
    ''' 
    This function is used to check if the answer generated by the VLM model contains the word "yes".
    
    Parameters
    ----------
    frame : np.ndarray
        The frame to analyze.
    question : str
        The question to ask.
    
    Returns
    -------
    bool
        A boolean indicating if the answer contains the word "yes".
    '''
    answer = generate_text_from_image_and_prompt(image = img(frame), prompt = question)
    return "yes" in answer.lower()